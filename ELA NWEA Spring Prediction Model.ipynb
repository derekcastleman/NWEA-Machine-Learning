{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1942e535",
   "metadata": {},
   "source": [
    "# ELA NWEA Spring Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e36647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82b871",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c4914",
   "metadata": {},
   "source": [
    "First the NWEA data for the Fall and Winter NWEA will be uploaded and joined using an outer join in order to keep any student who took a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686eb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel (r\"C:\\Users\\derek.castleman\\Desktop\\Testing Data\\NWEA History\\NWEA 2016-2022\\NWEA 2021-22\\Fall 2021-2022\\AssessmentResults 9-13-21.xlsx\") # Insert Fall file pathway between the parenthesis with a csv file\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['Subject'] == 'Language Arts'] #Selects the Language Arts test\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall = data[['TermName', 'StudentID', 'TestStartTime', 'TestDurationMinutes', 'TestRITScore', \n",
    "             'TestPercentile', 'PercentCorrect', 'RapidGuessingPercentage', 'Grade']] #Selects the needed data\n",
    "fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9beb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv (r\"C:\\Users\\derek.castleman\\Desktop\\Testing Data\\NWEA History\\NWEA 2016-2022\\NWEA 2021-22\\Winter 2021-2022\\AssessmentResults.csv\") #Insert pathway of the Winter NWEA test\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['Subject'] == 'Language Arts'] #Selects Language Arts test\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "winter = data[['TermName','StudentID', 'TestStartTime', 'TestDurationMinutes', \n",
    "               'TestRITScore', 'TestPercentile', 'PercentCorrect', 'RapidGuessingPercentage', 'Grade']] #Needed features\n",
    "winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "NWEA_Data = pd.merge(fall, winter, how='outer', \n",
    "                            left_on=['StudentID'], right_on=['StudentID']) #Joins the Fall and Winter data\n",
    "NWEA_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d4f83",
   "metadata": {},
   "source": [
    "## Fixing Missing Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258201d",
   "metadata": {},
   "source": [
    "For students that missed one of the NWEA tests their score for the missing exam will be filled in using the growth chart that is provided by NWEA for what should be expected for their scores based on the percentile that they were found to be in. Therefore, the percentile level they are at for the one test that they took will be then used to fill in the missing score.\n",
    "\n",
    "__*The excel file that contains the scores for each grade level and percentile will have to be uploaded at the point in which it is asked.*__\n",
    "\n",
    "The missing scores will be filled in one grade level at a time since the scores for each percentile vary by the grade in which the student is. The column will be changed to the name Fall Test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d417a5f",
   "metadata": {},
   "source": [
    "### Fall Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = NWEA_Data[NWEA_Data['TestRITScore_x'].isna()] #Finding students missing the Fall test.\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_data = pd.read_excel (r\"C:\\Users\\derek.castleman\\Desktop\\Testing Data\\ML NWEA SBAC\\Fall ELA NWEA.xlsx\") #Upload excel file pathway for ELA NWEA Fall scores\n",
    "fall_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c293da",
   "metadata": {},
   "source": [
    "Now each grade level will be separated, have the missing scores filled in, then combined at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61721fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = full_data.loc[full_data['Grade'] == 'K']\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa912f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.merge(fall_data[[0, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "k['TestRITScore_x'] = k['TestRITScore_x'].fillna(k[0])\n",
    "\n",
    "k.drop([0], inplace=True, axis=1)\n",
    "k.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416137f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first= full_data.loc[full_data['Grade'] == '1']\n",
    "first= first.merge(fall_data[[1, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "first['TestRITScore_x'] =first['TestRITScore_x'].fillna(first[1])\n",
    "\n",
    "first.drop([1], inplace=True, axis=1)\n",
    "first.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "second = full_data.loc[full_data['Grade'] == '2']\n",
    "second = second.merge(fall_data[[2, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "second['TestRITScore_x'] =second['TestRITScore_x'].fillna(second[2])\n",
    "\n",
    "second.drop([2], inplace=True, axis=1)\n",
    "second.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902aa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "third = full_data.loc[full_data['Grade'] == '3']\n",
    "third = third.merge(fall_data[[3, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "third['TestRITScore_x'] =third['TestRITScore_x'].fillna(third[3])\n",
    "\n",
    "third.drop([3], inplace=True, axis=1)\n",
    "third.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth = full_data.loc[full_data['Grade'] == '4']\n",
    "fourth = fourth.merge(fall_data[[4, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "fourth['TestRITScore_x'] =fourth['TestRITScore_x'].fillna(fourth[4])\n",
    "\n",
    "fourth.drop([4], inplace=True, axis=1)\n",
    "fourth.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth = full_data.loc[full_data['Grade'] == '5']\n",
    "fifth = fifth.merge(fall_data[[5, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "fifth['TestRITScore_x'] =fifth['TestRITScore_x'].fillna(fifth[5])\n",
    "\n",
    "fifth.drop([5], inplace=True, axis=1)\n",
    "fifth.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "fifth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth = full_data.loc[full_data['Grade'] == '6']\n",
    "sixth = sixth.merge(fall_data[[6, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "sixth['TestRITScore_x'] =sixth['TestRITScore_x'].fillna(sixth[6])\n",
    "\n",
    "sixth.drop([6], inplace=True, axis=1)\n",
    "sixth.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "sixth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seventh = full_data.loc[full_data['Grade'] == '7']\n",
    "seventh = seventh.merge(fall_data[[7, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "seventh['TestRITScore_x'] =seventh['TestRITScore_x'].fillna(seventh[7])\n",
    "\n",
    "seventh.drop([7], inplace=True, axis=1)\n",
    "seventh.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "seventh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff349788",
   "metadata": {},
   "outputs": [],
   "source": [
    "eighth = full_data.loc[full_data['Grade'] == '8']\n",
    "eighth = eighth.merge(fall_data[[8, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "eighth['TestRITScore_x'] =eighth['TestRITScore_x'].fillna(eighth[8])\n",
    "\n",
    "eighth.drop([8], inplace=True, axis=1)\n",
    "eighth.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "eighth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninth = full_data.loc[full_data['Grade'] == '9']\n",
    "ninth = ninth.merge(fall_data[[9, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "ninth['TestRITScore_x'] =ninth['TestRITScore_x'].fillna(ninth[9])\n",
    "\n",
    "ninth.drop([9], inplace=True, axis=1)\n",
    "ninth.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "ninth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenth = full_data.loc[full_data['Grade'] == '10']\n",
    "tenth = tenth.merge(fall_data[[10, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "tenth['TestRITScore_x'] =tenth['TestRITScore_x'].fillna(tenth[10])\n",
    "\n",
    "tenth.drop([10], inplace=True, axis=1)\n",
    "tenth.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "tenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3203ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eleventh = full_data.loc[full_data['Grade'] == '11']\n",
    "eleventh = eleventh.merge(fall_data[[11, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "eleventh['TestRITScore_x'] =eleventh['TestRITScore_x'].fillna(eleventh[11])\n",
    "\n",
    "eleventh.drop([11], inplace=True, axis=1)\n",
    "eleventh.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "eleventh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8863e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "twelfth = full_data.loc[full_data['Grade'] == '12']\n",
    "twelfth = twelfth.merge(fall_data[[12, 'TestPercentile_y']],on='TestPercentile_y',how=\"left\")\n",
    "\n",
    "twelfth['TestRITScore_x'] =twelfth['TestRITScore_x'].fillna(twelfth[12])\n",
    "\n",
    "twelfth.drop([12], inplace=True, axis=1)\n",
    "twelfth.rename(columns={'TestRITScore_x':'Fall Test'},inplace=True)\n",
    "twelfth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b44b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [k, first, second, third, fourth, fifth, sixth, seventh, eighth, ninth, tenth, eleventh, twelfth]\n",
    "full_data_fall = pd.concat(frames) # Combing all the grade levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column to Winter Test so it matches as others are changed\n",
    "full_data_fall.rename(columns = {'TestRITScore_y':'Winter Test'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2903fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_fall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de72ec7",
   "metadata": {},
   "source": [
    "### Winter Scores\n",
    "\n",
    "The same steps will now happen for students that mised the Winter Test.\n",
    "\n",
    "__*Remember to put the excel file for Winter NWEA chart in the proper place*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = NWEA_Data[NWEA_Data['TestRITScore_y'].isna()]\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcea480",
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_data = pd.read_excel (r\"\") #Insert pathway for Winter NWEA test scores here\n",
    "winter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb387ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = full_data.loc[full_data['Grade'] == 'K']\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.merge(winter_data[[0, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "k['TestRITScore_y'] = k['TestRITScore_y'].fillna(k[0])\n",
    "\n",
    "k.drop([0], inplace=True, axis=1)\n",
    "k.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65611896",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9922a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "first= full_data.loc[full_data['Grade'] == '1']\n",
    "first= first.merge(winter_data[[1, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "first['TestRITScore_y'] =first['TestRITScore_y'].fillna(first[1])\n",
    "\n",
    "first.drop([1], inplace=True, axis=1)\n",
    "first.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "second = full_data.loc[full_data['Grade'] == '2']\n",
    "second = second.merge(winter_data[[2, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "second['TestRITScore_y'] =second['TestRITScore_y'].fillna(second[2])\n",
    "\n",
    "second.drop([2], inplace=True, axis=1)\n",
    "second.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7af32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "third = full_data.loc[full_data['Grade'] == '3']\n",
    "third = third.merge(winter_data[[3, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "third['TestRITScore_y'] =third['TestRITScore_y'].fillna(third[3])\n",
    "\n",
    "third.drop([3], inplace=True, axis=1)\n",
    "third.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef132a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth = full_data.loc[full_data['Grade'] == '4']\n",
    "fourth = fourth.merge(winter_data[[4, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "fourth['TestRITScore_y'] =fourth['TestRITScore_y'].fillna(fourth[4])\n",
    "\n",
    "fourth.drop([4], inplace=True, axis=1)\n",
    "fourth.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6690be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth = full_data.loc[full_data['Grade'] == '5']\n",
    "fifth = fifth.merge(winter_data[[5, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "fifth['TestRITScore_y'] =fifth['TestRITScore_y'].fillna(fifth[5])\n",
    "\n",
    "fifth.drop([5], inplace=True, axis=1)\n",
    "fifth.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "fifth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth = full_data.loc[full_data['Grade'] == '6']\n",
    "sixth = sixth.merge(winter_data[[6, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "sixth['TestRITScore_y'] =sixth['TestRITScore_y'].fillna(sixth[6])\n",
    "\n",
    "sixth.drop([6], inplace=True, axis=1)\n",
    "sixth.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "sixth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seventh = full_data.loc[full_data['Grade'] == '7']\n",
    "seventh = seventh.merge(winter_data[[7, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "seventh['TestRITScore_y'] =seventh['TestRITScore_y'].fillna(seventh[7])\n",
    "\n",
    "seventh.drop([7], inplace=True, axis=1)\n",
    "seventh.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "seventh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eighth = full_data.loc[full_data['Grade'] == '8']\n",
    "eighth = eighth.merge(winter_data[[8, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "eighth['TestRITScore_y'] =eighth['TestRITScore_y'].fillna(eighth[8])\n",
    "\n",
    "eighth.drop([8], inplace=True, axis=1)\n",
    "eighth.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "eighth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ninth = full_data.loc[full_data['Grade'] == '9']\n",
    "ninth = ninth.merge(winter_data[[9, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "ninth['TestRITScore_y'] =ninth['TestRITScore_y'].fillna(ninth[9])\n",
    "\n",
    "ninth.drop([9], inplace=True, axis=1)\n",
    "ninth.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "ninth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenth = full_data.loc[full_data['Grade'] == '10']\n",
    "tenth = tenth.merge(winter_data[[10, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "tenth['TestRITScore_y'] =tenth['TestRITScore_y'].fillna(tenth[10])\n",
    "\n",
    "tenth.drop([10], inplace=True, axis=1)\n",
    "tenth.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "tenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eleventh = full_data.loc[full_data['Grade'] == '11']\n",
    "eleventh = eleventh.merge(winter_data[[11, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "eleventh['TestRITScore_y'] =eleventh['TestRITScore_y'].fillna(eleventh[11])\n",
    "\n",
    "eleventh.drop([11], inplace=True, axis=1)\n",
    "eleventh.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "eleventh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "twelfth = full_data.loc[full_data['Grade'] == '12']\n",
    "twelfth = twelfth.merge(winter_data[[12, 'TestPercentile_x']],on='TestPercentile_x',how=\"left\")\n",
    "\n",
    "twelfth['TestRITScore_y'] =twelfth['TestRITScore_y'].fillna(twelfth[12])\n",
    "\n",
    "twelfth.drop([12], inplace=True, axis=1)\n",
    "twelfth.rename(columns={'TestRITScore_y':'Winter Test'},inplace=True)\n",
    "twelfth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [k, first, second, third, fourth, fifth, sixth, seventh, eighth, ninth, tenth, eleventh, twelfth]\n",
    "full_data_winter = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b75b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_winter.rename(columns = {'TestRITScore_x':'Fall Test'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_winter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574eef61",
   "metadata": {},
   "source": [
    "### Students with both tests\n",
    "\n",
    "Students that took both tests will be selected so that the column names can be renamed and then allow them to be combined with the other two dataframes that were generated for students missing Fall and Winter tests to produce one final dataframe that has all Fall and Winter test score for students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856025cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting students that have all tests\n",
    "full_data_students = NWEA_Data.loc[NWEA_Data['TestRITScore_y'].notnull()]\n",
    "full_data_students = full_data_students.loc[full_2022['TestRITScore_x'].notnull()]\n",
    "full_data_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a01a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "full_data_students.rename(columns = {'TestRITScore_y':'Winter Test'}, inplace = True)\n",
    "full_data_students.rename(columns = {'TestRITScore_x':'Fall Test'}, inplace = True)\n",
    "full_data_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting all of the data together\n",
    "frames = [full_data_students, full_data_winter, full_data_fall]\n",
    "data_fixed = pd.concat(frames)\n",
    "data_fixed = data_fixed.drop_duplicates(subset='StudentID', keep=\"first\") #Dropping if duplicates exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1569afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fixed.info() #Checking the data for what is there and how many values missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c61f26",
   "metadata": {},
   "source": [
    "## Student Information\n",
    "\n",
    "Combing student information (ID, State ID, Gender and Language Fluency) that is taken from Aries in order to allow for combining of NWEA data with the ICA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5715e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.read_excel (r\"C:\\Users\\derek.castleman\\Desktop\\Testing Data\\ML NWEA SBAC\\FInal Data\\2021-2022 Student data.xlsx\")\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An inner join on NWEA data with student data since State ID is necessary for ICA join\n",
    "data_with_students = pd.merge(data_fixed, students, how='inner', left_on=['StudentID'], right_on=['Student ID'])\n",
    "data_with_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6913d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping any duplicated students\n",
    "data_fixed = data_with_students.drop_duplicates(subset='StudentID', keep=\"first\")\n",
    "data_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5242bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fixed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2a88d",
   "metadata": {},
   "source": [
    "## ICA Data\n",
    "\n",
    "The ICA data for the students will first be selected by narrowing the dataframe down by Subject then Assessment Subtype.\n",
    "\n",
    "The features that are wanted from the dataset will then be selected out.\n",
    "\n",
    "An inner join with the ICA data will occur between the ICA dataframe and the NWEA one. An inner join is completed since there is no way in which to fill in the score for the student in the same fashon there was with students who had missed either the Fall or Winter test.\n",
    "\n",
    "Basically, if a student has missed the ICA then there is not going to be a prediction for their Spring NWEA score from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef295ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = pd.read_excel (r\"C:\\Users\\derek.castleman\\Desktop\\Testing Data\\ML NWEA SBAC\\FInal Data\\ELAICA2022.xlsx\")\n",
    "ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica =ica.loc[ica['Subject'] == 'ELA'] #Selects the Language Arts test\n",
    "ica =ica.loc[ica['AssessmentSubType'] == 'ICA'] #Selects the ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ba36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects the features that are needed from the data\n",
    "ica = ica[['StudentIdentifier', 'AssessmentSubType', 'Subject', 'GradeLevelWhenAssessed', 'ScaleScoreAchievementLevel', \n",
    "             'ScaleScore', 'ScaleScoreStandardError', 'EnglishLanguageAcquisitionStatus']] #Selects the needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d889dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c168c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inner join between the ICA data and the NWEA data\n",
    "full_testing_data = pd.merge(data_fixed, ica, how='inner', \n",
    "                            left_on=['State Student ID'], right_on=['StudentIdentifier'])\n",
    "full_testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data after the join.\n",
    "full_testing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f22795",
   "metadata": {},
   "source": [
    "## Missing Values and Data Transformation\n",
    "\n",
    "Missing values from students who had their Fall or Winter test filled in have to be dealt with. Rapid Guessing and the percent correct will be the value that they obtained on the test they actually took since the score for the test is based on this as well.\n",
    "\n",
    "Categorical (language fluency) and one hot encoding (gender) will be used on the features to turn them into numbers for use in the ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df44f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = full_testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e59524",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549be2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Languge fluency is selected\n",
    "language = testing_data['LangFlu'].to_numpy()\n",
    "language = language.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_categories = ['L', 'R', 'I', 'E', 'F'] #Selecting the order for the categories for ordinalencoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinalencoder = OrdinalEncoder(categories=[scale_categories])\n",
    "\n",
    "scale_fixed = ordinalencoder.fit_transform(language) #The data is transformed to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ac21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa083743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changed into a dataframe\n",
    "scale_fixed_df = pd.DataFrame(scale_fixed, columns = ['Learner'])\n",
    "scale_fixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e31264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rejoined back with the original dataframe\n",
    "fixed_data = testing_data.join(scale_fixed_df)\n",
    "fixed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7257c994",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c25ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = fixed_data['Gender'].to_numpy() #Selecting Gender\n",
    "gender = gender.reshape(-1, 1) #Reshaping it for OneHotEncoder\n",
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing Gender to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehotencoder = OneHotEncoder(drop = 'first', sparse = False) #Dropping the first column since it is redundant\n",
    "\n",
    "student_gender = onehotencoder.fit_transform(gender)\n",
    "student_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.DataFrame(student_gender, columns = ['gender'])\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6daf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding gender as a column to the dataframe\n",
    "fixed_data['gender'] = gender_df\n",
    "fixed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Rapid Guessing to \n",
    "fixed_data['RapidGuessingPercentage_x'].fillna(fixed_data['RapidGuessingPercentage_y'], inplace = True)\n",
    "fixed_data['RapidGuessingPercentage_y'].fillna(fixed_data['RapidGuessingPercentage_x'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link( df, title = \"Testing_Data\", filename = \"Testing_Data\"):\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(fixed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f160382",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv (r\"C:\\Users\\derek.castleman\\Desktop\\Testing Data\\ML NWEA SBAC\\FInal Data\\Full_ELA_Training_Data.csv\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['RapidGuessingPercentage_x'].fillna(training_data['RapidGuessingPercentage_y'], inplace = True)\n",
    "training_data['RapidGuessingPercentage_y'].fillna(training_data['RapidGuessingPercentage_x'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcced380",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'RapidGuessingPercentage_x': 0, 'RapidGuessingPercentage_y': 0}\n",
    "training_data = training_data.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link( df, title = \"Training_Data_ELA_Finale\", filename = \"Training_Data_ELA_Finale\"):\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_data[['Fall Test', 'Winter Test', 'Grade', \"ScaleScore\", 'gender', 'RapidGuessingPercentage_x',\n",
    "                      'RapidGuessingPercentage_y', 'PercentCorrect_y', 'PercentCorrect_x']]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee118ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3cac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = training_data[['TestRITScore']]\n",
    "target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e13d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_scaler = StandardScaler()\n",
    "scaled_data = model_scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def display_scores(mode, X_train, y_train):\n",
    "    model_scores = cross_val_score(model, X_train, y_train,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "    scores = np.sqrt(-model_scores)\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ceeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores_r2(mode, X_train, y_train):\n",
    "    model_scores = cross_val_score(model, X_train, y_train,\n",
    "                         scoring=\"r2\", cv=5)\n",
    "    scores = model_scores\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6bb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features\n",
    "y_train = target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "display_scores(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a19fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "display_scores_r2(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c29fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y_train.to_numpy() #Have to change training data into an array and the shape of it for use in model.\n",
    "y_train = x.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d3479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "display_scores(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores_r2(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd52642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "display_scores(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ea10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores_r2(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "model = RidgeCV()\n",
    "display_scores(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores_r2(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8896aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('lr', LinearRegression()),('gbr_reg', GradientBoostingRegressor()), ('rfr', RandomForestRegressor())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StackingRegressor(estimators)\n",
    "display_scores(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe2bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "display_scores(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c8ff4",
   "metadata": {},
   "source": [
    "## Machine Learning Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f650bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_data = pd.read_csv (r\"C:\\Users\\derek.castleman\\Desktop\\Testing Data\\ML NWEA SBAC\\FInal Data\\Testing_Data_ELA_Finale.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf526d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_data['PercentCorrect_x'].fillna(fixed_data['PercentCorrect_y'], inplace = True)\n",
    "fixed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119393a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_data['PercentCorrect_y'].fillna(fixed_data['PercentCorrect_x'], inplace = True)\n",
    "fixed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fixed_data[['Fall Test', 'Winter Test', 'Grade', \"ScaleScore\", 'gender', 'RapidGuessingPercentage_x',\n",
    "                      'RapidGuessingPercentage_y', 'PercentCorrect_x', 'PercentCorrect_y']]\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = fixed_data[['TestRITScore']]\n",
    "target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5714e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_scaler = StandardScaler()\n",
    "scaled_data = model_scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd827bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = features\n",
    "y_test = target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d294100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link( df, title = \"Y_pred\", filename = \"Y_pred\"):\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5435820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link( df, title = \"Y_pred\", filename = \"Y_pred\"):\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
